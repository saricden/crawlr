<h1>Crawlr</h1>
Crawlr is a standalone web crawler that can run on any machine running a server stack with PHP.
To install, simply clone this repository to somewhere that can run PHP and open up /frontend.

The interface accepts a type of file to look for, and a keyword to scan for on pages. It keeps looking until one of three stop conditions is met.

I'm not sure if the distribution between front and back end is the most efficient, but it's fairly simple.

I started this project because between 2008 and 2014 I developed many flash games that were lost when Mochimedia ceased to exis. Thing is, most of the games were distributed across the web. So with luck, and a bit of decent code I'll be able to find them all!