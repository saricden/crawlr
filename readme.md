<h1>Crawlr</h1>
Crawlr is a standalone web crawler that can run on any machine running a server stack with PHP.
To install, simply clone this repository to somewhere that can run PHP and open up /frontend.

The interface accepts a type of file to look for, and a keyword to scan for on pages. It keeps looking until a stop condition is met.

I'm not sure if the distribution between front and back end is the most efficient, but it's fairly simple.

I started this project because between 2008 and 2014 I developed many flash games that were lost when Mochimedia went belly up. Thing is, most of the games were distributed across the web. So with luck, and a bit of good code I'll be able to find them!
